#!/usr/bin/env python3
"""
è³‡æ–™è¨˜éŒ„æ¨¡çµ„ (Data Logger Module)
è¨˜éŒ„ä¸¦ä¿å­˜REBAåˆ†æçµæœ

åŠŸèƒ½ï¼š
1. è¨˜éŒ„æ¯ä¸€å¹€çš„åˆ†æçµæœï¼ˆè§’åº¦ã€REBAåˆ†æ•¸ã€é¢¨éšªç­‰ç´šï¼‰
2. ä¿å­˜ç‚ºCSVè¡¨æ ¼æ ¼å¼ï¼ˆé©åˆExcelåˆ†æï¼‰
3. ä¿å­˜ç‚ºJSONçµæ§‹åŒ–æ ¼å¼ï¼ˆåŒ…å«å®Œæ•´è³‡è¨Šå’Œçµ±è¨ˆï¼‰
4. è‡ªå‹•è¨ˆç®—çµ±è¨ˆè³‡è¨Šï¼ˆå¹³å‡å€¼ã€æ¨™æº–å·®ã€åˆ†ä½ˆç­‰ï¼‰
5. ç”Ÿæˆåˆ†æå ±å‘Š
6. è³‡æ–™é©—è­‰å’Œå“è³ªæª¢æŸ¥

æ”¯æ´æ ¼å¼:
- CSV: è¡¨æ ¼æ ¼å¼ï¼Œé©åˆçµ±è¨ˆåˆ†æå’ŒExcelè™•ç†
- JSON: çµæ§‹åŒ–æ ¼å¼ï¼ŒåŒ…å«å®Œæ•´è³‡è¨Šå’Œå…ƒè³‡æ–™
- Markdown: åˆ†æå ±å‘Šæ ¼å¼

ä½œè€…ï¼šäººå› å·¥ç¨‹ç ”ç©¶åœ˜éšŠ
æ—¥æœŸï¼š2025å¹´1æœˆ
ç‰ˆæœ¬ï¼š1.0
"""

import csv
import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
from collections import deque
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    logger.warning("Pandasæœªå®‰è£ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")


# ==================== ç·šä¸Šçµ±è¨ˆç´¯ç©å™¨ ====================

class OnlineStats:
    """
    ç·šä¸Šçµ±è¨ˆè¨ˆç®—å™¨ï¼ˆä½¿ç”¨Welfordç®—æ³•ï¼‰
    O(1)è¨˜æ†¶é«”è¤‡é›œåº¦ï¼Œé©åˆè™•ç†ç„¡é™è³‡æ–™æµ

    åƒè€ƒï¼šhttps://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm
    """

    def __init__(self):
        """åˆå§‹åŒ–çµ±è¨ˆè¨ˆç®—å™¨"""
        self.count = 0
        self.mean = 0.0
        self.m2 = 0.0  # sum of squares of differences from mean
        self.min_val = float('inf')
        self.max_val = float('-inf')

    def update(self, value: float):
        """
        æ›´æ–°çµ±è¨ˆå€¼

        Args:
            value: æ–°æ•¸æ“šé»
        """
        if value is None:
            return

        self.count += 1
        delta = value - self.mean
        self.mean += delta / self.count
        delta2 = value - self.mean
        self.m2 += delta * delta2

        self.min_val = min(self.min_val, value)
        self.max_val = max(self.max_val, value)

    def get_stats(self) -> Dict[str, float]:
        """
        ç²å–çµ±è¨ˆçµæœ

        Returns:
            çµ±è¨ˆå­—å…¸ï¼ŒåŒ…å« count, mean, std, min, max
        """
        if self.count == 0:
            return {'count': 0, 'mean': 0, 'std': 0, 'min': 0, 'max': 0}

        variance = self.m2 / self.count if self.count > 0 else 0
        std = variance ** 0.5

        return {
            'count': self.count,
            'mean': round(self.mean, 2),
            'std': round(std, 2),
            'min': round(self.min_val, 2) if self.min_val != float('inf') else 0,
            'max': round(self.max_val, 2) if self.max_val != float('-inf') else 0
        }


class StatisticsAccumulator:
    """
    çµ±è¨ˆè³‡æ–™ç´¯ç©å™¨
    ä½¿ç”¨ç·šä¸Šæ¼”ç®—æ³•é€²è¡ŒO(1)è¨˜æ†¶é«”çš„çµ±è¨ˆè¨ˆç®—
    """

    def __init__(self):
        """åˆå§‹åŒ–æ‰€æœ‰çµ±è¨ˆè¿½è¹¤å™¨"""
        # REBAåˆ†æ•¸çµ±è¨ˆ
        self.reba_stats = OnlineStats()

        # è§’åº¦çµ±è¨ˆ
        self.angle_stats = {
            'neck_angle': OnlineStats(),
            'trunk_angle': OnlineStats(),
            'upper_arm_angle': OnlineStats(),
            'forearm_angle': OnlineStats(),
            'wrist_angle': OnlineStats(),
            'leg_angle': OnlineStats()
        }

        # é¢¨éšªç­‰ç´šè¨ˆæ•¸
        self.risk_counts = {
            'negligible': 0,
            'low': 0,
            'medium': 0,
            'high': 0,
            'very_high': 0
        }

        # æ™‚é–“è¿½è¹¤
        self.first_timestamp = None
        self.last_timestamp = None
        self.total_frames = 0
        self.valid_frames = 0

    def update(self, record: Dict):
        """
        æ›´æ–°ç´¯ç©çµ±è¨ˆ

        Args:
            record: å–®å¹€è¨˜éŒ„
        """
        self.total_frames += 1

        # æ›´æ–°REBAçµ±è¨ˆ
        reba_score = record.get('reba_score')
        if reba_score is not None:
            self.valid_frames += 1
            self.reba_stats.update(float(reba_score))

        # æ›´æ–°è§’åº¦çµ±è¨ˆ
        for angle_name in self.angle_stats:
            angle_value = record.get(angle_name)
            if angle_value is not None:
                self.angle_stats[angle_name].update(float(angle_value))

        # æ›´æ–°é¢¨éšªç­‰ç´šè¨ˆæ•¸
        risk_level = record.get('risk_level')
        if risk_level in self.risk_counts:
            self.risk_counts[risk_level] += 1

        # æ›´æ–°æ™‚é–“è¿½è¹¤
        timestamp = record.get('timestamp')
        if timestamp is not None:
            if self.first_timestamp is None:
                self.first_timestamp = timestamp
            self.last_timestamp = timestamp

    def get_statistics(self) -> Dict[str, Any]:
        """
        ç²å–å®Œæ•´çµ±è¨ˆçµæœ

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        # åŸºæœ¬çµ±è¨ˆ
        basic_stats = {
            'total_frames': self.total_frames,
            'valid_frames': self.valid_frames,
            'invalid_frames': self.total_frames - self.valid_frames,
            'success_rate': round(self.valid_frames / self.total_frames * 100, 2) if self.total_frames > 0 else 0
        }

        # REBAåˆ†æ•¸çµ±è¨ˆ
        reba_stats = self.reba_stats.get_stats()
        if reba_stats['count'] > 0:
            # è¨ˆç®—ä¸­ä½æ•¸å’Œå››åˆ†ä½æ•¸éœ€è¦å¯¦éš›è³‡æ–™ï¼Œé€™è£¡æä¾›åŸºæœ¬ä¼°è¨ˆ
            reba_stats['median'] = reba_stats['mean']
            reba_stats['q25'] = max(1, reba_stats['mean'] - reba_stats['std'])
            reba_stats['q75'] = min(15, reba_stats['mean'] + reba_stats['std'])

        # é¢¨éšªç­‰ç´šåˆ†ä½ˆ
        total_risk = sum(self.risk_counts.values())
        risk_percentages = {
            level: round(count / total_risk * 100, 2) if total_risk > 0 else 0
            for level, count in self.risk_counts.items()
        }

        # è§’åº¦çµ±è¨ˆ
        angle_stats_dict = {
            name: stats.get_stats()
            for name, stats in self.angle_stats.items()
            if stats.count > 0
        }

        # æ™‚é–“çµ±è¨ˆ
        duration = 0
        avg_fps = 0
        if self.first_timestamp is not None and self.last_timestamp is not None:
            duration = self.last_timestamp - self.first_timestamp
            avg_fps = self.total_frames / duration if duration > 0 else 0

        return {
            'basic': basic_stats,
            'reba_score': reba_stats,
            'risk_distribution': {
                'counts': self.risk_counts.copy(),
                'percentages': risk_percentages
            },
            'angles': angle_stats_dict,
            'time': {
                'duration_seconds': round(duration, 2),
                'average_fps': round(avg_fps, 2)
            }
        }


class DataLogger:
    """
    è³‡æ–™è¨˜éŒ„å™¨
    
    æä¾›å®Œæ•´çš„è³‡æ–™è¨˜éŒ„å’Œä¿å­˜åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - å¹€è³‡æ–™è¨˜éŒ„
    - CSV/JSONæ ¼å¼ä¿å­˜
    - çµ±è¨ˆåˆ†æ
    - å ±å‘Šç”Ÿæˆ
    """
    
    def __init__(self, output_dir: str = './results'):
        """
        åˆå§‹åŒ–è³‡æ–™è¨˜éŒ„å™¨

        Args:
            output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘
        """
        self.output_dir = Path(output_dir)

        # ä½¿ç”¨å›ºå®šå¤§å°çš„dequeå„²å­˜æœ€è¿‘1000å¹€ï¼ˆç”¨æ–¼å³æ™‚æŸ¥è©¢ï¼‰
        # è¨˜æ†¶é«”ç”¨é‡ï¼š1000å¹€ Ã— ç´„2KB = 2MBï¼ˆå›ºå®šï¼‰
        self.recent_buffer = deque(maxlen=10000)

        # ä¸²æµå¯«å…¥æ¨¡å¼
        self.csv_file = None
        self.csv_writer = None
        self.is_recording = False

        # ç·šä¸Šçµ±è¨ˆç´¯ç©å™¨ï¼ˆO(1)è¨˜æ†¶é«”ï¼‰
        self.stats_accumulator = StatisticsAccumulator()

        self.session_start = datetime.now()  # æœƒè©±é–‹å§‹æ™‚é–“
        self.session_id = self.session_start.strftime("%Y%m%d_%H%M%S")  # æœƒè©±ID

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è³‡æ–™æ¬„ä½å®šç¾©
        self.data_fields = [
            'frame_id',          # å¹€ç·¨è™Ÿ
            'timestamp',         # æ™‚é–“æˆ³
            'datetime',          # æ—¥æœŸæ™‚é–“
            'neck_angle',        # é ¸éƒ¨è§’åº¦
            'trunk_angle',       # è»€å¹¹è§’åº¦
            'upper_arm_angle',   # ä¸Šè‡‚è§’åº¦
            'forearm_angle',     # å‰è‡‚è§’åº¦
            'wrist_angle',       # æ‰‹è…•è§’åº¦
            'leg_angle',         # è…¿éƒ¨è§’åº¦
            'reba_score',        # REBAåˆ†æ•¸
            'risk_level',        # é¢¨éšªç­‰ç´š
        ]

        logger.info(f"è³‡æ–™è¨˜éŒ„å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info(f"æœƒè©±ID: {self.session_id}")
        logger.info(f"ä¸²æµæ¨¡å¼: è¨˜æ†¶é«”ç”¨é‡å›ºå®š < 10MB")
    
    # ==================== ä¸²æµéŒ„è£½æ§åˆ¶ ====================

    def start_recording(self, base_filename: Optional[str] = None):
        """
        é–‹å§‹ä¸²æµéŒ„è£½

        Args:
            base_filename: æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰ï¼ŒNoneå‰‡è‡ªå‹•ç”Ÿæˆ
        """
        if self.is_recording:
            logger.warning("å·²åœ¨éŒ„è£½ä¸­ï¼Œè«‹å…ˆåœæ­¢")
            return

        # ç”Ÿæˆæª”æ¡ˆåç¨±
        if base_filename is None:
            base_filename = f"reba_analysis_{self.session_id}"

        filepath = self.output_dir / f"{base_filename}.csv"

        try:
            # é–‹å•ŸCSVæª”æ¡ˆé€²è¡Œä¸²æµå¯«å…¥
            self.csv_file = open(filepath, 'w', newline='', encoding='utf-8-sig')
            self.csv_writer = csv.DictWriter(self.csv_file, fieldnames=self.data_fields)
            self.csv_writer.writeheader()

            self.is_recording = True
            logger.info(f"é–‹å§‹éŒ„è£½: {filepath}")
            logger.info("ä¸²æµæ¨¡å¼: æ¯å¹€å³æ™‚å¯«å…¥ï¼Œè¨˜æ†¶é«”ç”¨é‡ < 10MB")

        except Exception as e:
            logger.error(f"ç„¡æ³•é–‹å§‹éŒ„è£½: {e}")
            if self.csv_file:
                self.csv_file.close()
                self.csv_file = None

    def stop_recording(self):
        """åœæ­¢ä¸²æµéŒ„è£½"""
        if not self.is_recording:
            logger.warning("æœªåœ¨éŒ„è£½ä¸­")
            return

        try:
            if self.csv_file:
                self.csv_file.close()
                self.csv_file = None

            self.csv_writer = None
            self.is_recording = False

            logger.info("éŒ„è£½å·²åœæ­¢")
            logger.info(f"ç¸½å¹€æ•¸: {self.stats_accumulator.total_frames}")

        except Exception as e:
            logger.error(f"åœæ­¢éŒ„è£½æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # ==================== è³‡æ–™è¨˜éŒ„æ–¹æ³• ====================

    def add_frame_data(self, frame_id: int, timestamp: float,
                      angles: Dict[str, Optional[float]],
                      reba_score: int,
                      risk_level: str,
                      details: Optional[Dict] = None,
                      metadata: Optional[Dict] = None):
        """
        æ·»åŠ ä¸€å¹€çš„è³‡æ–™ï¼ˆä¸²æµæ¨¡å¼ï¼‰

        Args:
            frame_id: å¹€ç·¨è™Ÿ
            timestamp: æ™‚é–“æˆ³ï¼ˆç§’ï¼‰
            angles: è§’åº¦å­—å…¸ï¼ŒåŒ…å«6å€‹é—œç¯€è§’åº¦
            reba_score: REBAåˆ†æ•¸
            risk_level: é¢¨éšªç­‰ç´š
            details: è©³ç´°åˆ†æ•¸å­—å…¸ï¼ˆå¯é¸ï¼‰
            metadata: é¡å¤–çš„å…ƒè³‡æ–™ï¼ˆå¯é¸ï¼‰
        """
        # æ§‹å»ºåŸºæœ¬è¨˜éŒ„
        record = {
            'frame_id': frame_id,
            'timestamp': timestamp,
            'datetime': datetime.fromtimestamp(timestamp).isoformat(),
            'neck_angle': angles.get('neck'),
            'trunk_angle': angles.get('trunk'),
            'upper_arm_angle': angles.get('upper_arm'),
            'forearm_angle': angles.get('forearm'),
            'wrist_angle': angles.get('wrist'),
            'leg_angle': angles.get('leg'),
            'reba_score': reba_score,
            'risk_level': risk_level
        }

        # æ·»åŠ è©³ç´°åˆ†æ•¸ï¼ˆå¦‚æœæä¾›ï¼‰
        if details:
            for key, value in details.items():
                if key not in record:
                    record[f'detail_{key}'] = value

        # æ·»åŠ å…ƒè³‡æ–™ï¼ˆå¦‚æœæä¾›ï¼‰
        if metadata:
            for key, value in metadata.items():
                if key not in record:
                    record[f'meta_{key}'] = value

        # 1. å³æ™‚å¯«å…¥CSVï¼ˆä¸²æµæ¨¡å¼ï¼‰
        if self.is_recording and self.csv_writer:
            try:
                self.csv_writer.writerow(record)
                self.csv_file.flush()  # ç¢ºä¿å³æ™‚å¯«å…¥ç£ç¢Ÿ
            except Exception as e:
                logger.error(f"CSVå¯«å…¥å¤±æ•—: {e}")

        # 2. æ·»åŠ åˆ°recent_bufferï¼ˆå›ºå®šå¤§å°ï¼Œè‡ªå‹•æ·˜æ±°èˆŠè³‡æ–™ï¼‰
        self.recent_buffer.append(record)

        # 3. æ›´æ–°ç·šä¸Šçµ±è¨ˆï¼ˆO(1)è¨˜æ†¶é«”ï¼‰
        self.stats_accumulator.update(record)

        # æ¯100å¹€è¨˜éŒ„ä¸€æ¬¡æ—¥èªŒ
        if self.stats_accumulator.total_frames % 100 == 0:
            logger.debug(f"å·²è¨˜éŒ„ {self.stats_accumulator.total_frames} å¹€è³‡æ–™ï¼ˆè¨˜æ†¶é«”: {len(self.recent_buffer)} å¹€å¿«å–ï¼‰")
    
    def add_batch_data(self, batch_data: List[Dict]):
        """
        æ‰¹æ¬¡æ·»åŠ è³‡æ–™ï¼ˆç”¨æ–¼ç›¸å®¹æ€§ï¼Œä¸å»ºè­°åœ¨ä¸²æµæ¨¡å¼ä½¿ç”¨ï¼‰

        Args:
            batch_data: è³‡æ–™åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚ºä¸€å¹€çš„è³‡æ–™å­—å…¸
        """
        for data in batch_data:
            # å¯«å…¥CSVï¼ˆå¦‚æœæ­£åœ¨éŒ„è£½ï¼‰
            if self.is_recording and self.csv_writer:
                try:
                    self.csv_writer.writerow(data)
                except Exception as e:
                    logger.error(f"æ‰¹æ¬¡å¯«å…¥CSVå¤±æ•—: {e}")

            # æ·»åŠ åˆ°recent_buffer
            self.recent_buffer.append(data)

            # æ›´æ–°çµ±è¨ˆ
            self.stats_accumulator.update(data)

        # ç¢ºä¿æ‰¹æ¬¡å¯«å…¥ç£ç¢Ÿ
        if self.is_recording and self.csv_file:
            self.csv_file.flush()

        logger.info(f"æ‰¹æ¬¡æ·»åŠ  {len(batch_data)} ç­†è³‡æ–™")
    
    # ==================== CSVä¿å­˜æ–¹æ³• ====================
    
    def save_to_csv(self, filename: Optional[str] = None,
                   include_details: bool = False) -> str:
        """
        ä¿å­˜recent_bufferç‚ºCSVæª”æ¡ˆï¼ˆåƒ…åŒ…å«æœ€è¿‘1000å¹€ï¼‰

        æ³¨æ„ï¼šåœ¨ä¸²æµæ¨¡å¼ä¸‹ï¼Œè³‡æ–™å·²å³æ™‚å¯«å…¥CSVï¼Œæ­¤æ–¹æ³•åƒ…ä¿å­˜recent_buffer

        Args:
            filename: æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰ï¼ŒNoneå‰‡è‡ªå‹•ç”Ÿæˆ
            include_details: æ˜¯å¦åŒ…å«è©³ç´°åˆ†æ•¸æ¬„ä½

        Returns:
            ä¿å­˜çš„æª”æ¡ˆè·¯å¾‘
        """
        if not self.recent_buffer:
            logger.warning("recent_bufferç‚ºç©ºï¼Œç„¡è³‡æ–™å¯ä¿å­˜")
            return ""

        # ç”Ÿæˆæª”æ¡ˆåç¨±
        if filename is None:
            filename = f"reba_recent_{self.session_id}"

        filepath = self.output_dir / f"{filename}.csv"

        try:
            if PANDAS_AVAILABLE:
                # ä½¿ç”¨pandasä¿å­˜
                df = pd.DataFrame(list(self.recent_buffer))

                # é¸æ“‡è¦ä¿å­˜çš„æ¬„ä½
                if not include_details:
                    columns = [col for col in df.columns
                              if not col.startswith('detail_') and not col.startswith('meta_')]
                    df = df[columns]

                # æ’åºæ¬„ä½
                if 'frame_id' in df.columns:
                    df = df.sort_values('frame_id')

                # ä¿å­˜
                df.to_csv(filepath, index=False, encoding='utf-8-sig')

            else:
                # ä½¿ç”¨æ¨™æº–åº«ä¿å­˜
                with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
                    # ç¢ºå®šæ¬„ä½
                    if include_details:
                        fieldnames = list(self.recent_buffer[0].keys())
                    else:
                        fieldnames = [f for f in self.recent_buffer[0].keys()
                                    if not f.startswith('detail_') and not f.startswith('meta_')]

                    writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                    writer.writeheader()

                    # å¯«å…¥è³‡æ–™
                    for record in self.recent_buffer:
                        writer.writerow(record)

            logger.info(f"CSVæª”æ¡ˆå·²ä¿å­˜: {filepath}")
            logger.info(f"è¨˜éŒ„æ•¸: {len(self.recent_buffer)}ï¼ˆæœ€è¿‘1000å¹€ï¼‰")

            return str(filepath)

        except Exception as e:
            logger.error(f"CSVä¿å­˜å¤±æ•—: {e}")
            return ""
    
    # ==================== JSONä¿å­˜æ–¹æ³• ====================
    
    def save_to_json(self, filename: Optional[str] = None,
                    include_statistics: bool = True,
                    pretty_print: bool = True) -> str:
        """
        ä¿å­˜çµ±è¨ˆè³‡è¨Šç‚ºJSONæª”æ¡ˆ

        Args:
            filename: æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰ï¼ŒNoneå‰‡è‡ªå‹•ç”Ÿæˆ
            include_statistics: æ˜¯å¦åŒ…å«çµ±è¨ˆè³‡è¨Š
            pretty_print: æ˜¯å¦æ ¼å¼åŒ–è¼¸å‡ºï¼ˆç¸®æ’ï¼‰

        Returns:
            ä¿å­˜çš„æª”æ¡ˆè·¯å¾‘
        """
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        if filename is None:
            filename = f"reba_stats_{self.session_id}"

        filepath = self.output_dir / f"{filename}.json"

        try:
            # æ§‹å»ºJSONçµæ§‹
            data = {
                'session_info': {
                    'session_id': self.session_id,
                    'start_time': self.session_start.isoformat(),
                    'end_time': datetime.now().isoformat(),
                    'total_frames': self.stats_accumulator.total_frames,
                    'recent_buffer_size': len(self.recent_buffer),
                    'output_directory': str(self.output_dir)
                },
                'recent_frames': list(self.recent_buffer)  # æœ€è¿‘1000å¹€
            }

            # æ·»åŠ çµ±è¨ˆè³‡è¨Š
            if include_statistics:
                data['statistics'] = self.get_statistics()

            # ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                if pretty_print:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                else:
                    json.dump(data, f, ensure_ascii=False)

            logger.info(f"JSONæª”æ¡ˆå·²ä¿å­˜: {filepath}")
            logger.info(f"ç¸½å¹€æ•¸: {self.stats_accumulator.total_frames}ï¼Œrecent_buffer: {len(self.recent_buffer)}å¹€")

            return str(filepath)

        except Exception as e:
            logger.error(f"JSONä¿å­˜å¤±æ•—: {e}")
            return ""
    
    # ==================== çµ±è¨ˆåˆ†ææ–¹æ³• ====================
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        ç²å–çµ±è¨ˆè³‡è¨Šï¼ˆä½¿ç”¨ç·šä¸Šç´¯ç©å™¨ï¼ŒO(1)è¨˜æ†¶é«”ï¼‰

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸ï¼ŒåŒ…å«ï¼š
            - åŸºæœ¬çµ±è¨ˆï¼ˆç¸½æ•¸ã€æœ‰æ•ˆæ•¸ï¼‰
            - REBAåˆ†æ•¸çµ±è¨ˆï¼ˆå¹³å‡ã€æ¨™æº–å·®ã€ç¯„åœï¼‰
            - é¢¨éšªç­‰ç´šåˆ†ä½ˆ
            - è§’åº¦çµ±è¨ˆï¼ˆå„é—œç¯€ï¼‰
            - æ™‚é–“çµ±è¨ˆ
        """
        try:
            return self.stats_accumulator.get_statistics()
        except Exception as e:
            logger.error(f"çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}")
            return {}
    
    # ==================== å ±å‘Šç”Ÿæˆæ–¹æ³• ====================
    
    def print_summary(self):
        """åˆ—å°æ‘˜è¦è³‡è¨Šåˆ°æ§åˆ¶å°"""
        stats = self.get_statistics()
        
        print("\n" + "="*60)
        print("REBA åˆ†ææ‘˜è¦")
        print("="*60)
        
        if not stats:
            print("æ²’æœ‰çµ±è¨ˆè³‡æ–™")
            return
        
        # åŸºæœ¬è³‡è¨Š
        if 'basic' in stats:
            basic = stats['basic']
            print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
            print(f"  ç¸½å¹€æ•¸: {basic.get('total_frames', 0)}")
            print(f"  æœ‰æ•ˆå¹€æ•¸: {basic.get('valid_frames', 0)}")
            print(f"  æˆåŠŸç‡: {basic.get('success_rate', 0):.1f}%")
        
        # REBAåˆ†æ•¸çµ±è¨ˆ
        if 'reba_score' in stats:
            reba = stats['reba_score']
            print(f"\nğŸ¯ REBAåˆ†æ•¸çµ±è¨ˆ:")
            print(f"  å¹³å‡åˆ†æ•¸: {reba.get('mean', 0):.2f}")
            print(f"  æ¨™æº–å·®: {reba.get('std', 0):.2f}")
            print(f"  åˆ†æ•¸ç¯„åœ: {reba.get('min', 0)} - {reba.get('max', 0)}")
            if 'median' in reba:
                print(f"  ä¸­ä½æ•¸: {reba.get('median', 0):.2f}")
        
        # é¢¨éšªç­‰ç´šåˆ†ä½ˆ
        if 'risk_distribution' in stats:
            print(f"\nâš ï¸  é¢¨éšªç­‰ç´šåˆ†ä½ˆ:")
            
            risk_names = {
                'negligible': 'å¯å¿½ç•¥',
                'low': 'ä½é¢¨éšª',
                'medium': 'ä¸­ç­‰é¢¨éšª',
                'high': 'é«˜é¢¨éšª',
                'very_high': 'æ¥µé«˜é¢¨éšª'
            }
            
            dist = stats['risk_distribution']
            counts = dist.get('counts', {})
            percentages = dist.get('percentages', {})
            
            for risk_level in ['negligible', 'low', 'medium', 'high', 'very_high']:
                if risk_level in counts:
                    count = counts[risk_level]
                    pct = percentages.get(risk_level, 0)
                    name = risk_names.get(risk_level, risk_level)
                    print(f"  {name}: {count}æ¬¡ ({pct:.1f}%)")
        
        # è§’åº¦çµ±è¨ˆ
        if 'angles' in stats and stats['angles']:
            print(f"\nğŸ“ è§’åº¦çµ±è¨ˆ:")
            
            angle_names = {
                'neck_angle': 'é ¸éƒ¨',
                'trunk_angle': 'è»€å¹¹',
                'upper_arm_angle': 'ä¸Šè‡‚',
                'forearm_angle': 'å‰è‡‚',
                'wrist_angle': 'æ‰‹è…•',
                'leg_angle': 'è…¿éƒ¨'
            }
            
            for angle_key, angle_data in stats['angles'].items():
                name = angle_names.get(angle_key, angle_key)
                mean = angle_data.get('mean', 0)
                std = angle_data.get('std', 0)
                print(f"  {name}: {mean:.1f}Â° (Â±{std:.1f}Â°)")
        
        # æ™‚é–“çµ±è¨ˆ
        if 'time' in stats:
            time_stats = stats['time']
            duration = time_stats.get('duration_seconds', 0)
            fps = time_stats.get('average_fps', 0)
            print(f"\nâ±ï¸  æ™‚é–“çµ±è¨ˆ:")
            print(f"  ç¸½æ™‚é•·: {duration:.2f}ç§’")
            print(f"  å¹³å‡FPS: {fps:.2f}")
        
        print("="*60 + "\n")
    
    def generate_markdown_report(self, filename: Optional[str] = None) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†æå ±å‘Š
        
        Args:
            filename: æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰
            
        Returns:
            ä¿å­˜çš„æª”æ¡ˆè·¯å¾‘
        """
        if not self.data_buffer:
            logger.warning("æ²’æœ‰è³‡æ–™å¯ç”Ÿæˆå ±å‘Š")
            return ""
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        if filename is None:
            filename = f"reba_report_{self.session_id}"
        
        filepath = self.output_dir / f"{filename}.md"
        
        try:
            stats = self.get_statistics()
            
            with open(filepath, 'w', encoding='utf-8') as f:
                # æ¨™é¡Œ
                f.write("# REBA åˆ†æå ±å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"**æœƒè©±ID**: {self.session_id}\n\n")
                f.write("---\n\n")
                
                # åŸºæœ¬çµ±è¨ˆ
                if 'basic' in stats:
                    f.write("## ğŸ“Š åŸºæœ¬çµ±è¨ˆ\n\n")
                    basic = stats['basic']
                    f.write(f"- **ç¸½å¹€æ•¸**: {basic.get('total_frames', 0)}\n")
                    f.write(f"- **æœ‰æ•ˆå¹€æ•¸**: {basic.get('valid_frames', 0)}\n")
                    f.write(f"- **ç„¡æ•ˆå¹€æ•¸**: {basic.get('invalid_frames', 0)}\n")
                    f.write(f"- **æˆåŠŸç‡**: {basic.get('success_rate', 0):.1f}%\n\n")
                
                # REBAåˆ†æ•¸çµ±è¨ˆ
                if 'reba_score' in stats:
                    f.write("## ğŸ¯ REBAåˆ†æ•¸çµ±è¨ˆ\n\n")
                    reba = stats['reba_score']
                    f.write(f"- **å¹³å‡åˆ†æ•¸**: {reba.get('mean', 0):.2f}\n")
                    f.write(f"- **æ¨™æº–å·®**: {reba.get('std', 0):.2f}\n")
                    f.write(f"- **æœ€å°å€¼**: {reba.get('min', 0)}\n")
                    f.write(f"- **æœ€å¤§å€¼**: {reba.get('max', 0)}\n")
                    f.write(f"- **ä¸­ä½æ•¸**: {reba.get('median', 0):.2f}\n\n")
                
                # é¢¨éšªç­‰ç´šåˆ†ä½ˆ
                if 'risk_distribution' in stats:
                    f.write("## âš ï¸ é¢¨éšªç­‰ç´šåˆ†ä½ˆ\n\n")
                    
                    risk_names = {
                        'negligible': 'å¯å¿½ç•¥é¢¨éšª',
                        'low': 'ä½é¢¨éšª',
                        'medium': 'ä¸­ç­‰é¢¨éšª',
                        'high': 'é«˜é¢¨éšª',
                        'very_high': 'æ¥µé«˜é¢¨éšª'
                    }
                    
                    dist = stats['risk_distribution']
                    counts = dist.get('counts', {})
                    percentages = dist.get('percentages', {})
                    
                    f.write("| é¢¨éšªç­‰ç´š | æ¬¡æ•¸ | ç™¾åˆ†æ¯” |\n")
                    f.write("|---------|------|--------|\n")
                    
                    for risk_level in ['negligible', 'low', 'medium', 'high', 'very_high']:
                        if risk_level in counts:
                            count = counts[risk_level]
                            pct = percentages.get(risk_level, 0)
                            name = risk_names.get(risk_level, risk_level)
                            f.write(f"| {name} | {count} | {pct:.1f}% |\n")
                    
                    f.write("\n")
                
                # è§’åº¦çµ±è¨ˆ
                if 'angles' in stats and stats['angles']:
                    f.write("## ğŸ“ é—œç¯€è§’åº¦çµ±è¨ˆ\n\n")
                    
                    angle_names = {
                        'neck_angle': 'é ¸éƒ¨',
                        'trunk_angle': 'è»€å¹¹',
                        'upper_arm_angle': 'ä¸Šè‡‚',
                        'forearm_angle': 'å‰è‡‚',
                        'wrist_angle': 'æ‰‹è…•',
                        'leg_angle': 'è…¿éƒ¨'
                    }
                    
                    f.write("| éƒ¨ä½ | å¹³å‡å€¼ | æ¨™æº–å·® | æœ€å°å€¼ | æœ€å¤§å€¼ |\n")
                    f.write("|------|--------|--------|--------|--------|\n")
                    
                    for angle_key, angle_data in stats['angles'].items():
                        name = angle_names.get(angle_key, angle_key)
                        mean = angle_data.get('mean', 0)
                        std = angle_data.get('std', 0)
                        min_val = angle_data.get('min', 0)
                        max_val = angle_data.get('max', 0)
                        f.write(f"| {name} | {mean:.1f}Â° | {std:.1f}Â° | {min_val:.1f}Â° | {max_val:.1f}Â° |\n")
                    
                    f.write("\n")
                
                # æ™‚é–“çµ±è¨ˆ
                if 'time' in stats:
                    f.write("## â±ï¸ æ™‚é–“çµ±è¨ˆ\n\n")
                    time_stats = stats['time']
                    duration = time_stats.get('duration_seconds', 0)
                    fps = time_stats.get('average_fps', 0)
                    f.write(f"- **ç¸½æ™‚é•·**: {duration:.2f}ç§’\n")
                    f.write(f"- **å¹³å‡FPS**: {fps:.2f}\n\n")
                
                # å»ºè­°
                f.write("## ğŸ’¡ å»ºè­°\n\n")
                
                # æ ¹æ“šé¢¨éšªåˆ†ä½ˆçµ¦å‡ºå»ºè­°
                if 'risk_distribution' in stats:
                    counts = stats['risk_distribution'].get('counts', {})
                    total = sum(counts.values())
                    
                    high_risk_count = counts.get('high', 0) + counts.get('very_high', 0)
                    high_risk_pct = (high_risk_count / total * 100) if total > 0 else 0
                    
                    if high_risk_pct > 30:
                        f.write("âš ï¸ **è­¦å‘Š**: æª¢æ¸¬åˆ°å¤§é‡é«˜é¢¨éšªå‹•ä½œï¼ˆ{:.1f}%ï¼‰\n\n".format(high_risk_pct))
                        f.write("å»ºè­°ï¼š\n")
                        f.write("1. ç«‹å³æª¢è¨å·¥ä½œæµç¨‹å’Œå§¿å‹¢\n")
                        f.write("2. æä¾›äººå› å·¥ç¨‹åŸ¹è¨“\n")
                        f.write("3. è€ƒæ…®ä½¿ç”¨è¼”åŠ©è¨­å‚™\n")
                        f.write("4. å®‰æ’å®šæœŸä¼‘æ¯æ™‚é–“\n\n")
                    elif high_risk_pct > 10:
                        f.write("âš ï¸ **æ³¨æ„**: æª¢æ¸¬åˆ°éƒ¨åˆ†é«˜é¢¨éšªå‹•ä½œï¼ˆ{:.1f}%ï¼‰\n\n".format(high_risk_pct))
                        f.write("å»ºè­°ï¼š\n")
                        f.write("1. è­˜åˆ¥ä¸¦æ”¹å–„é«˜é¢¨éšªå‹•ä½œ\n")
                        f.write("2. åŠ å¼·äººå› å·¥ç¨‹æ„è­˜\n")
                        f.write("3. å®šæœŸé€²è¡Œå§¿å‹¢è©•ä¼°\n\n")
                    else:
                        f.write("âœ… **è‰¯å¥½**: å¤§éƒ¨åˆ†å‹•ä½œåœ¨å¯æ¥å—ç¯„åœå…§\n\n")
                        f.write("å»ºè­°ï¼š\n")
                        f.write("1. æŒçºŒä¿æŒè‰¯å¥½å·¥ä½œå§¿å‹¢\n")
                        f.write("2. å®šæœŸé€²è¡Œè‡ªæˆ‘æª¢æŸ¥\n")
                        f.write("3. æ³¨æ„é¿å…ç–²å‹ç´¯ç©\n\n")
                
                f.write("---\n\n")
                f.write("*æœ¬å ±å‘Šç”±REBAåˆ†æç³»çµ±è‡ªå‹•ç”Ÿæˆ*\n")
            
            logger.info(f"Markdownå ±å‘Šå·²ä¿å­˜: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return ""
    
    # ==================== è³‡æ–™ç®¡ç†æ–¹æ³• ====================

    def clear_buffer(self):
        """æ¸…ç©ºrecent_bufferå’Œçµ±è¨ˆï¼ˆä¸å½±éŸ¿å·²å¯«å…¥CSVçš„è³‡æ–™ï¼‰"""
        self.recent_buffer.clear()
        self.stats_accumulator = StatisticsAccumulator()
        self.session_start = datetime.now()
        self.session_id = self.session_start.strftime("%Y%m%d_%H%M%S")
        logger.info("recent_bufferå’Œçµ±è¨ˆå·²é‡ç½®")

    def get_buffer_size(self) -> int:
        """
        ç²å–recent_bufferå¤§å°

        Returns:
            recent_bufferä¸­çš„è¨˜éŒ„ç­†æ•¸ï¼ˆæœ€å¤š1000ï¼‰
        """
        return len(self.recent_buffer)

    def get_total_frames(self) -> int:
        """
        ç²å–ç¸½è™•ç†å¹€æ•¸

        Returns:
            ç´¯è¨ˆè™•ç†çš„ç¸½å¹€æ•¸
        """
        return self.stats_accumulator.total_frames

    def get_frame_data(self, frame_id: int) -> Optional[Dict]:
        """
        ç²å–ç‰¹å®šå¹€çš„è³‡æ–™ï¼ˆåƒ…æœå°‹recent_bufferä¸­çš„æœ€è¿‘1000å¹€ï¼‰

        Args:
            frame_id: å¹€ç·¨è™Ÿ

        Returns:
            è©²å¹€çš„è³‡æ–™å­—å…¸ï¼Œè‹¥ä¸å­˜åœ¨å‰‡è¿”å›None
        """
        for record in self.recent_buffer:
            if record.get('frame_id') == frame_id:
                return record
        return None

    def get_data_by_time_range(self, start_time: float, end_time: float) -> List[Dict]:
        """
        ç²å–æ™‚é–“ç¯„åœå…§çš„è³‡æ–™ï¼ˆåƒ…æœå°‹recent_bufferä¸­çš„æœ€è¿‘1000å¹€ï¼‰

        Args:
            start_time: èµ·å§‹æ™‚é–“æˆ³
            end_time: çµæŸæ™‚é–“æˆ³

        Returns:
            ç¬¦åˆæ¢ä»¶çš„è³‡æ–™åˆ—è¡¨
        """
        return [record for record in self.recent_buffer
                if start_time <= record.get('timestamp', 0) <= end_time]

    def filter_by_risk_level(self, risk_level: str) -> List[Dict]:
        """
        æŒ‰é¢¨éšªç­‰ç´šç¯©é¸è³‡æ–™ï¼ˆåƒ…æœå°‹recent_bufferä¸­çš„æœ€è¿‘1000å¹€ï¼‰

        Args:
            risk_level: é¢¨éšªç­‰ç´š

        Returns:
            ç¬¦åˆæ¢ä»¶çš„è³‡æ–™åˆ—è¡¨
        """
        return [record for record in self.recent_buffer
                if record.get('risk_level') == risk_level]

    def get_high_risk_frames(self, threshold: int = 8) -> List[Dict]:
        """
        ç²å–é«˜é¢¨éšªå¹€ï¼ˆåƒ…æœå°‹recent_bufferä¸­çš„æœ€è¿‘1000å¹€ï¼‰

        Args:
            threshold: REBAåˆ†æ•¸é–¾å€¼ï¼Œå¤§æ–¼ç­‰æ–¼æ­¤å€¼è¦–ç‚ºé«˜é¢¨éšª

        Returns:
            é«˜é¢¨éšªå¹€åˆ—è¡¨
        """
        return [record for record in self.recent_buffer
                if record.get('reba_score', 0) >= threshold]
    
    # ==================== è³‡æ–™åŒ¯å‡ºæ–¹æ³• ====================
    
    def export_summary_only(self, filename: Optional[str] = None) -> str:
        """
        åƒ…åŒ¯å‡ºçµ±è¨ˆæ‘˜è¦ï¼ˆä¸å«é€å¹€è³‡æ–™ï¼‰
        
        Args:
            filename: æª”æ¡ˆåç¨±
            
        Returns:
            ä¿å­˜çš„æª”æ¡ˆè·¯å¾‘
        """
        if filename is None:
            filename = f"reba_summary_{self.session_id}"
        
        filepath = self.output_dir / f"{filename}.json"
        
        try:
            summary = {
                'session_info': {
                    'session_id': self.session_id,
                    'start_time': self.session_start.isoformat(),
                    'end_time': datetime.now().isoformat()
                },
                'statistics': self.get_statistics()
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æ‘˜è¦å·²ä¿å­˜: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"æ‘˜è¦åŒ¯å‡ºå¤±æ•—: {e}")
            return ""
    
    def save_all_formats(self, base_filename: Optional[str] = None) -> Dict[str, str]:
        """
        ä¿å­˜æ‰€æœ‰æ ¼å¼ï¼ˆCSVã€JSONã€Markdownå ±å‘Šï¼‰
        
        Args:
            base_filename: åŸºç¤æª”æ¡ˆåç¨±
            
        Returns:
            å„æ ¼å¼æª”æ¡ˆè·¯å¾‘å­—å…¸
        """
        if base_filename is None:
            base_filename = f"reba_analysis_{self.session_id}"
        
        results = {}
        
        # ä¿å­˜CSV
        csv_path = self.save_to_csv(base_filename)
        if csv_path:
            results['csv'] = csv_path
        
        # ä¿å­˜JSON
        json_path = self.save_to_json(base_filename)
        if json_path:
            results['json'] = json_path
        
        # ç”ŸæˆMarkdownå ±å‘Š
        md_path = self.generate_markdown_report(base_filename)
        if md_path:
            results['markdown'] = md_path
        
        logger.info(f"å·²ä¿å­˜ {len(results)} ç¨®æ ¼å¼")
        return results
    
    # ==================== è³‡æ–™é©—è­‰æ–¹æ³• ====================
    
    def validate_data(self) -> Dict[str, Any]:
        """
        é©—è­‰recent_bufferè³‡æ–™å“è³ª

        Returns:
            é©—è­‰çµæœå­—å…¸
        """
        if not self.recent_buffer:
            return {'valid': False, 'message': 'recent_bufferç‚ºç©º'}

        issues = []
        warnings = []

        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_fields = ['frame_id', 'timestamp', 'reba_score', 'risk_level']
        for i, record in enumerate(self.recent_buffer):
            for field in required_fields:
                if field not in record or record[field] is None:
                    issues.append(f"è¨˜éŒ„{i}: ç¼ºå°‘æ¬„ä½ {field}")

        # æª¢æŸ¥REBAåˆ†æ•¸ç¯„åœ
        for i, record in enumerate(self.recent_buffer):
            score = record.get('reba_score')
            if score is not None and (score < 1 or score > 15):
                warnings.append(f"è¨˜éŒ„{i}: REBAåˆ†æ•¸ {score} è¶…å‡ºæ­£å¸¸ç¯„åœ(1-15)")

        # æª¢æŸ¥è§’åº¦ç¯„åœ
        angle_ranges = {
            'neck_angle': (0, 90),
            'trunk_angle': (0, 90),
            'upper_arm_angle': (0, 180),
            'forearm_angle': (0, 180),
            'wrist_angle': (0, 90),
            'leg_angle': (0, 180)
        }

        for i, record in enumerate(self.recent_buffer):
            for angle_name, (min_val, max_val) in angle_ranges.items():
                angle = record.get(angle_name)
                if angle is not None and (angle < 0 or angle > max_val):
                    warnings.append(f"è¨˜éŒ„{i}: {angle_name} {angle:.1f}Â° å¯èƒ½ç•°å¸¸")

        # æª¢æŸ¥æ™‚é–“é †åº
        timestamps = [r.get('timestamp', 0) for r in self.recent_buffer]
        if timestamps != sorted(timestamps):
            warnings.append("æ™‚é–“æˆ³é †åºä¸é€£çºŒ")

        # ç”Ÿæˆé©—è­‰çµæœ
        validation = {
            'valid': len(issues) == 0,
            'total_records': len(self.recent_buffer),
            'total_frames_processed': self.stats_accumulator.total_frames,
            'issues': issues,
            'warnings': warnings,
            'issue_count': len(issues),
            'warning_count': len(warnings)
        }

        if validation['valid']:
            logger.info("è³‡æ–™é©—è­‰é€šé")
        else:
            logger.warning(f"è³‡æ–™é©—è­‰å¤±æ•—: {len(issues)} å€‹å•é¡Œ")

        return validation


# ==================== è¼”åŠ©å‡½æ•¸ ====================

def create_sample_data(num_frames: int = 100) -> List[Dict]:
    """
    å‰µå»ºæ¨£æœ¬è³‡æ–™ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
    
    Args:
        num_frames: å¹€æ•¸
        
    Returns:
        æ¨£æœ¬è³‡æ–™åˆ—è¡¨
    """
    import random
    
    sample_data = []
    start_time = datetime.now().timestamp()
    
    for i in range(num_frames):
        angles = {
            'neck': random.uniform(10, 40),
            'trunk': random.uniform(15, 60),
            'upper_arm': random.uniform(100, 160),
            'forearm': random.uniform(60, 120),
            'wrist': random.uniform(0, 30),
            'leg': random.uniform(150, 180)
        }
        
        # ç°¡å–®çš„REBAè¨ˆç®—ï¼ˆåƒ…ç”¨æ–¼ç¤ºä¾‹ï¼‰
        reba_score = random.randint(1, 12)
        
        if reba_score <= 3:
            risk_level = 'low'
        elif reba_score <= 7:
            risk_level = 'medium'
        elif reba_score <= 10:
            risk_level = 'high'
        else:
            risk_level = 'very_high'
        
        record = {
            'frame_id': i,
            'timestamp': start_time + i * 0.033,  # ç´„30fps
            'neck_angle': angles['neck'],
            'trunk_angle': angles['trunk'],
            'upper_arm_angle': angles['upper_arm'],
            'forearm_angle': angles['forearm'],
            'wrist_angle': angles['wrist'],
            'leg_angle': angles['leg'],
            'reba_score': reba_score,
            'risk_level': risk_level
        }
        
        sample_data.append(record)
    
    return sample_data


# ==================== æ¸¬è©¦ä»£ç¢¼ ====================

if __name__ == "__main__":
    print("="*60)
    print("è³‡æ–™è¨˜éŒ„å™¨æ¸¬è©¦")
    print("="*60)
    
    # å‰µå»ºè¨˜éŒ„å™¨
    logger_test = DataLogger('./test_results')
    print(f"\nâœ“ è¨˜éŒ„å™¨å·²å‰µå»ºï¼Œè¼¸å‡ºç›®éŒ„: {logger_test.output_dir}")
    
    # ç”Ÿæˆæ¸¬è©¦è³‡æ–™
    print("\nğŸ“ ç”Ÿæˆæ¸¬è©¦è³‡æ–™...")
    test_data = create_sample_data(200)
    logger_test.add_batch_data(test_data)
    print(f"âœ“ å·²æ·»åŠ  {len(test_data)} ç­†è³‡æ–™")
    
    # åˆ—å°æ‘˜è¦
    print("\n" + "-"*60)
    logger_test.print_summary()
    
    # ä¿å­˜æ‰€æœ‰æ ¼å¼
    print("-"*60)
    print("\nğŸ’¾ ä¿å­˜è³‡æ–™...")
    saved_files = logger_test.save_all_formats("test_analysis")
    
    for format_type, filepath in saved_files.items():
        print(f"âœ“ {format_type.upper()}: {filepath}")
    
    # è³‡æ–™é©—è­‰
    print("\nğŸ” é©—è­‰è³‡æ–™...")
    validation = logger_test.validate_data()
    if validation['valid']:
        print("âœ“ è³‡æ–™é©—è­‰é€šé")
    else:
        print(f"âš  ç™¼ç¾ {validation['issue_count']} å€‹å•é¡Œ")
        print(f"âš  ç™¼ç¾ {validation['warning_count']} å€‹è­¦å‘Š")
    
    # é«˜é¢¨éšªå¹€åˆ†æ
    print("\nâš ï¸ é«˜é¢¨éšªå¹€åˆ†æ...")
    high_risk_frames = logger_test.get_high_risk_frames(threshold=8)
    print(f"é«˜é¢¨éšªå¹€æ•¸: {len(high_risk_frames)} / {logger_test.get_buffer_size()}")
    print(f"é«˜é¢¨éšªæ¯”ä¾‹: {len(high_risk_frames)/logger_test.get_buffer_size()*100:.1f}%")
    
    print("\n" + "="*60)
    print("æ¸¬è©¦å®Œæˆï¼")
    print("="*60)